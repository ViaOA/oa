

G1
    http://www.infoq.com/articles/G1-One-Garbage-Collector-To-Rule-Them-All


-Xms  -Xmx 
pause time goal:  -XX:MaxGCPauseMillis

SET HOUR=%time:~0,2%
SET dtStamp9=%date:~-4%%date:~4,2%%date:~7,2%_0%time:~1,1%%time:~3,2%%time:~6,2% 
SET dtStamp24=%date:~-4%%date:~4,2%%date:~7,2%_%time:~0,2%%time:~3,2%%time:~6,2%
if "%HOUR:~0,1%" == " " (SET dtStamp=%dtStamp9%) else (SET dtStamp=%dtStamp24%)

-XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:%dtStamp%_gc.log

-Xmx<n>[g|m|k]
-XX:MaxPermSize=<n>[g|m|k]


qqqqqqqqqqqqq


Twitter PPt on GC

• Throughput collectors
• -XX:+UseSerialGC
• -XX:+UseParallelGC
• -XX:+UseParallelOldGC
• Low-pause collectors
• -XX:+UseConcMarkSweepGC
• -XX:+UseG1GC (can’t discuss it here)

• Throughput collectors can automatically tune themselves:
• -XX:+UseAdaptiveSizePolicy
• -XX:MaxGCPauseMillis=… (i.e. 100)
• -XX:GCTimeRatio=… (i.e. 19)


• Bulk service: throughput collector, no adaptive sizing policy.
• Everything else: try throughput collector with
adaptive sizing policy. If it didn’t work, use
concurrent mark-and-sweep (CMS).


Always start with tuning
the young generation
• Enable -XX:+PrintGCDetails, -XX:+PrintHeapAtGC,
and -XX:+PrintTenuringDistribution.
• Watch survivor sizes! You’ll need to determine
“desired survivor size”.
• There’s no such thing as a “desired eden size”, mind
you. The bigger, the better, with some
responsiveness caveats.
• Watch the tenuring threshold; might need to tune it
to tenure long lived objects faster.

-XX:+PrintHeapAtGC
Heap after GC invocations=7000 (full 87):
    par new generation total 4608000K, used 398455K
        eden space 4096000K, 0% used
        from space 512000K, 77% used
        to space 512000K, 0% used
    concurrent mark-sweep generation total 3072000K, used 1565157K
    concurrent-mark-sweep perm gen total 53256K, used 31889K
}

-XX:+PrintTenuringDistribution
Desired survivor size 262144000 bytes, new threshold 4 (max 4)
- age 1: 137474336 bytes, 137474336 total
- age 2: 37725496 bytes, 175199832 total
- age 3: 23551752 bytes, 198751584 total
- age 4: 14772272 bytes, 213523856 total

• Things of interest:
  • Number of ages
     • Size distribution in ages
        • You want strongly


Tuning the CMS
    • Give your app as much memory as possible.
        • CMS is speculative. More memory, less punitive miscalculations.
    • Try using CMS without tuning. Use -verbosegc and
        -XX:+PrintGCDetails.
    • Didn’t get any “Full GC” messages? You’re done!
    • Otherwise, tune the young generation first.

Tuning the old generation
    • Goals:
        • Keep the fragmentation low.
        • Avoid full GC stops.
    • Fortunately, the two goals are not conflicting.

    • Find the minimum and maximum working set size (observe “Full GC” numbers under stable state and under load).
    • Overprovision the numbers by 25-33%.
    • This gives CMS a cushion to concurrently clean memory as it’s used.

    • Find the minimum and maximum working set size (observe “Full GC” numbers under stable state and under load).
    • Overprovision the numbers by 25-33%.
    • This gives CMS a cushion to concurrently clean memory as it’s used.


Shane's PPt
    http://icespace/docs/DOC-14923

Parallel/Throughput Collector (default) - one thread per CPU, "stop the world"
    pros: multi CPUs, shorter pauses
    cons: sync required, fragmentation, long full GC pauses
     
Serial Collector - single thread
    pros: simpler alg, effficient, 
    cons: longer pauses, single cpu
    
Concurrent Mark-Sweep Collector (CMS)
    "low pause collector", paralel colleciton of young generation, mostly concurrent collection of old generation while app executes
    pros: shorter full gc
    cons: larger footprint required, more complex scheduling, slower allocation

Garbage First (G1)

Recommendations:
    Serial collector is used for client-style applications that do not have a requirement for low pause times
    Default collector is used for server-style applications that run on multi-processor machines and do not have pause time constraints (e.g., batch processing)
    CMS collector is used for server-style applications that run on multi-processor machines and have strict pause time requirements

Enable GC logging:
    -verbose:gc or -XX:+PrintGC
    Parse logs with GCViewer, GCPortal, or PrintGCStats awk script
    use Jconsole, visualVM, jstat
        
GC Logs
    Frequent Full GCs:
        [Full GC [PSYoungGen: 7702K->0K(121024K)] [PSOldGen: 1045917K->742424K(1048576K)] 1053620K->742424K(1169600K) [PSPermGen: 22650K->22650K(47104K)], 1.2624910 secs]
    Larger than expected Minor GC pauses:
        [GC [PSYoungGen: 112240K->16368K(60160K)] 157394K->78743K(1108736K), 0.1345240 secs]
    GC Overhead > 1%
    check out "GC Portal", GCViewer
    VisualVM has "Visual GC" plugin
     
jstat -gcutil -t 3868 1s 30
 Time    S0     S1     E        O      P YGC YGCT FGC   FGCT    GCT
313.7 0.00 99.99 4.20 84.56 0.15 2093 3.653    416 13.998 17.651
314.6 0.00 99.99 0.00 97.66 0.15 2100 3.665    417 14.023 17.688
315.6 0.00   0.00 0.00 71.25 0.15 2106 3.674    419 14.090 17.764
316.7 0.00 99.99 4.20 84.56 0.15 2113 3.687    420 14.124 17.811
317.7 0.00 99.99 0.00 97.66 0.15 2120 3.699    421 14.158 17.858
    
Why do Garbage Collections take so long?
    Young collection
        Copying live objects
        Promoting live objects to the old generation
    Old collection
        Compacting live objects by copying them
        Disposing of dead objects is extremely fast
    Verify that you’re not over-committed on memory (swapping)

Out of Memory
    -XX:+HeapDumpOnOutOfMemoryError
        Produces binary heap dump that can be read by VisualVM or jhat
    jmap
        Can produce binary heap dump on a running Java process or from a core file
        Produces histogram of live objects in heap of a running Java process
    use Visual to analyze a heap dump

Increasing CMSInitiatingOccupanyFraction for FXMR
    http://icespace/docs/DOC-12772
     -XX:CMSInitiatingOccupancyFraction 
     -XX:CMSInitiatingOccupancyFraction=50
        background: minor GCs in cms cause fragmentation, which can lead to a "promotion failure" when there
        is not enough continguous space in he Tenured Generation, which will require a full compacting GC to run.
        By setting this value (a percentage), it tells at what point to run:
           To avoid promotion failures, we set CMSInitiatingOccupancyFraction very aggressively.  
           For example, by setting it to 50, a CMS collection triggers when Tenured Generation is 50% full. 
           This leaves us with a very large buffer of continguous, unused, unfragmented space in Tenured 
           Generation ... so a promotion failure is highly unlikely.
        FYI, the default setting for CMSInitiatingOccupancyFraction is 90.

http://icespace/docs/DOC-16233
    JVM debug logging of the CMS free list by adding the flag -XX:PrintFLSStatistics=2.  
        This logging reports the state of the CMS free list at the time of garbage collection            
            
            
Lower the CompilThreashold for JIT 











